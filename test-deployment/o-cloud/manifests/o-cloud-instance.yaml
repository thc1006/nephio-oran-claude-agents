# Sample O-Cloud Instance
# This creates an O-Cloud with SMO integration and resource pools
apiVersion: ocloud.oran.io/v1alpha1
kind: OCloud
metadata:
  name: test-ocloud
  namespace: ocloud-system
  labels:
    environment: test
    region: us-west
    nephio.org/managed: "true"
  annotations:
    ocloud.oran.io/description: "Test O-Cloud deployment for Nephio R5 and O-RAN L Release"
spec:
  # Infrastructure type
  infrastructureType: kubernetes
  
  # Deployment regions
  regions:
  - us-west-1
  - us-west-2
  
  # SMO Configuration
  smo:
    enabled: true
    endpoint: http://smo-stub.ocloud-system.svc.cluster.local:8091
    authType: bearer
    aimlEnabled: true
    capabilities:
    - resource-management
    - policy-enforcement
    - alarm-handling
    - performance-monitoring
    - ai-ml-optimization
  
  # O2 Interface Configuration
  o2Interface:
    enabled: true
    version: "1.0"
    authEnabled: false
    endpoints:
    - /o2ims/v1/resourcePools
    - /o2ims/v1/resources
    - /o2ims/v1/deployments
    - /o2ims/v1/inventory
    - /o2ims/v1/alarms
    - /o2ims/v1/subscriptions
  
  # Resource Pools
  resourcePools:
  - name: edge-compute-pool
    type: compute
    location: edge-site-1
    capacity:
      cpu: "1000"
      memory: "4Ti"
      storage: "100Ti"
      network: "100Gbps"
    labels:
      tier: edge
      availability: high
      hardware: baremetal
  
  - name: central-compute-pool
    type: compute
    location: central-dc-1
    capacity:
      cpu: "5000"
      memory: "20Ti"
      storage: "1Pi"
      network: "400Gbps"
    labels:
      tier: central
      availability: critical
      hardware: virtualized
  
  - name: gpu-accelerator-pool
    type: accelerator
    location: ai-cluster-1
    capacity:
      cpu: "500"
      memory: "2Ti"
      storage: "50Ti"
      network: "200Gbps"
    labels:
      tier: specialized
      accelerator: nvidia-a100
      purpose: ai-ml
---
# Edge Resource Pool with detailed configuration
apiVersion: ocloud.oran.io/v1alpha1
kind: ResourcePool
metadata:
  name: edge-site-1-pool
  namespace: ocloud-system
  labels:
    site: edge-site-1
    managed-by: ocloud-controller
spec:
  type: compute
  location: edge-site-1
  capacity:
    cpu: "256"
    memory: "1Ti"
    storage: "20Ti"
    network: "25Gbps"
  nodeSelector:
    node-role.kubernetes.io/edge: "true"
    hardware-type: "baremetal"
  tolerations:
  - key: "edge-node"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
---
# Central Resource Pool
apiVersion: ocloud.oran.io/v1alpha1
kind: ResourcePool
metadata:
  name: central-dc-1-pool
  namespace: ocloud-system
  labels:
    site: central-dc-1
    managed-by: ocloud-controller
spec:
  type: compute
  location: central-dc-1
  capacity:
    cpu: "2048"
    memory: "8Ti"
    storage: "500Ti"
    network: "100Gbps"
  nodeSelector:
    node-role.kubernetes.io/compute: "true"
    datacenter: "central"
---
# GPU Accelerator Pool for AI/ML workloads
apiVersion: ocloud.oran.io/v1alpha1
kind: ResourcePool
metadata:
  name: gpu-pool-1
  namespace: ocloud-system
  labels:
    accelerator-type: gpu
    managed-by: ocloud-controller
spec:
  type: accelerator
  location: ai-cluster-1
  capacity:
    cpu: "128"
    memory: "512Gi"
    storage: "10Ti"
    network: "100Gbps"
    gpu: "8"  # 8 GPUs
  nodeSelector:
    accelerator: "nvidia-gpu"
    gpu-type: "a100"
  tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"